
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>A Brief Introduction to ML &amp; AI &#8212; Introduction to Engineering</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Engineering</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Introduction to Engineering
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1_Introduction_to_Machine_Learning.html">
   1. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_linear_regression.html">
   2. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3_Logistic_regression.html">
   3. Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4_KNN.html">
   4. K nearest Neighbors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="5_SVM.html">
   5. Support Vector Machine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="6_Decision_trees_and_random_forests.html">
   6. Decision Trees &amp; Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="7_Bayesian_methods.html">
   7. Naive Bayesian Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="8_k_means.html">
   8. K-Means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="9_Principal_Component_Analysis.html">
   9. Principal Component Analysis
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/IntroductiontoMachineLearning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Fangli-Ying/Introduction2Engineering/master?urlpath=tree/IntroductiontoMachineLearning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://jupyter.org/hub/hub/user-redirect/git-pull?repo=https://github.com/Fangli-Ying/Introduction2Engineering&urlpath=tree/Introduction2Engineering/IntroductiontoMachineLearning.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Fangli-Ying/Introduction2Engineering/blob/master/IntroductiontoMachineLearning.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   A Brief Introduction to ML &amp; AI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-science-vs-machine-learning-vs-artificial-intelligence">
     Data Science VS Machine Learning VS Artificial Intelligence
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-artificial-intelligence-ai">
   What is artificial intelligence (AI)?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   Machine Learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-involves-observing-and-studying-data-or-experiences-to-identify-patterns-and-set-up-a-reasoning-system-based-on-the-findings-the-various-components-of-machine-learning-include">
     Machine learning involves observing and studying data or experiences to identify patterns and set up a reasoning system based on the findings. The various components of machine learning include:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-in-a-nutshell">
     Machine Learning in a nutshell
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#typology-of-ml-systems">
     Typology of ML systems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-predicting-discrete-labels">
     Classification: Predicting discrete labels
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regression-predicting-continuous-labels">
       Regression: Predicting continuous labels
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#clustering-inferring-labels-on-unlabeled-data">
       Clustering: Inferring labels on unlabeled data
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dimensionality-reduction-inferring-structure-of-unlabeled-data">
       Dimensionality reduction: Inferring structure of unlabeled data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>A Brief Introduction to ML & AI</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   A Brief Introduction to ML &amp; AI
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-science-vs-machine-learning-vs-artificial-intelligence">
     Data Science VS Machine Learning VS Artificial Intelligence
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-artificial-intelligence-ai">
   What is artificial intelligence (AI)?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   Machine Learning
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-involves-observing-and-studying-data-or-experiences-to-identify-patterns-and-set-up-a-reasoning-system-based-on-the-findings-the-various-components-of-machine-learning-include">
     Machine learning involves observing and studying data or experiences to identify patterns and set up a reasoning system based on the findings. The various components of machine learning include:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-in-a-nutshell">
     Machine Learning in a nutshell
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#typology-of-ml-systems">
     Typology of ML systems
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-predicting-discrete-labels">
     Classification: Predicting discrete labels
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regression-predicting-continuous-labels">
       Regression: Predicting continuous labels
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#clustering-inferring-labels-on-unlabeled-data">
       Clustering: Inferring labels on unlabeled data
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dimensionality-reduction-inferring-structure-of-unlabeled-data">
       Dimensionality reduction: Inferring structure of unlabeled data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="a-brief-introduction-to-ml-ai">
<h1>A Brief Introduction to ML &amp; AI<a class="headerlink" href="#a-brief-introduction-to-ml-ai" title="Permalink to this headline">¶</a></h1>
<div class="section" id="data-science-vs-machine-learning-vs-artificial-intelligence">
<h2>Data Science VS Machine Learning VS Artificial Intelligence<a class="headerlink" href="#data-science-vs-machine-learning-vs-artificial-intelligence" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://www.mygreatlearning.com/blog/difference-data-science-machine-learning-ai/">Link</a></p>
<p><img alt="VS" src="_images/rl.PNG" /></p>
<p><img alt="Table" src="_images/dsmlai.PNG" /></p>
<p>‘<strong>What is Data Science?</strong>’,</p>
<ul class="simple">
<li><p>Data science is a broad field of study pertaining to data systems and processes, aimed at maintaining data sets and deriving meaning out of them.</p></li>
<li><p>Data scientists use a combination of tools, applications, principles and algorithms to make sense of random data clusters. Since almost all kinds of organizations today are generating exponential amounts of data around the world, it becomes difficult to monitor and store this data.</p></li>
<li><p>Data science focuses on data modelling and data warehousing to track the ever-growing data set. The information extracted through data science applications are used to guide business processes and reach organisational goals.</p></li>
</ul>
<p><a class="reference external" href="https://youtu.be/Nrfht_c3T7w">Video:What is Data Science)?</a></p>
<p>Data science uses a wide array of data-oriented technologies including SQL, Python, R, and Hadoop, etc. However, it also makes extensive use of statistical analysis, data visualization, distributed architecture, and more to extract meaning out of sets of data.</p>
<p>Data scientists are skilled professionals whose expertise allows them to quickly switch roles at any point in the life cycle of data science projects. They can work with Artificial Intelligence and machine learning with equal ease. In fact, data scientists need machine learning skills for specific requirements</p>
</div>
</div>
<div class="section" id="what-is-artificial-intelligence-ai">
<h1>What is artificial intelligence (AI)?<a class="headerlink" href="#what-is-artificial-intelligence-ai" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://youtu.be/nASDYRkbQIY">Video:What is AI (Artificial Intelligence)?</a></p>
<p><strong>Artificial intelligence</strong> is the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing, speech recognition and machine vision</p>
<ul class="simple">
<li><p><strong>How does AI work?</strong>
In general, AI systems work by ingesting large amounts of labeled training data, analyzing the data for correlations and patterns, and using these patterns to make predictions about future states. In this way, a chatbot that is fed examples of text chats can learn to produce lifelike exchanges with people, or an image recognition tool can learn to identify and describe objects in images by reviewing millions of examples. Often what they refer to as AI is simply one component of AI, such as <strong>machine learning</strong>. AI requires a foundation of specialized hardware and software for writing and training machine learning algorithms
.</p></li>
</ul>
<p><a class="reference external" href="https://youtu.be/0oRVLf16CMU">Video:What is AI (Artificial Intelligence)?</a></p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>In many ways, machine learning is the primary means by which data science manifests itself to the broader world. Machine learning is where these computational and algorithmic skills of data science meet the statistical thinking of data science, and the result is a collection of approaches to inference and data exploration that are not about effective theory so much as effective computation.</p></li>
<li><p>The term “<strong>machine learning</strong>” is sometimes thrown around as if it is some kind of magic pill: apply machine learning to your data, and all your problems will be solved! As you might expect, the reality is rarely this simple.</p></li>
<li><p>While these methods can be incredibly powerful, to be effective they must be approached with a firm grasp of the strengths and weaknesses of each method, as well as a grasp of general concepts such as bias and variance, overfitting and underfitting, and more.</p></li>
</ul>
<div class="section" id="machine-learning-involves-observing-and-studying-data-or-experiences-to-identify-patterns-and-set-up-a-reasoning-system-based-on-the-findings-the-various-components-of-machine-learning-include">
<h2>Machine learning involves observing and studying data or experiences to identify patterns and set up a reasoning system based on the findings. The various components of machine learning include:<a class="headerlink" href="#machine-learning-involves-observing-and-studying-data-or-experiences-to-identify-patterns-and-set-up-a-reasoning-system-based-on-the-findings-the-various-components-of-machine-learning-include" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><strong>Supervised machine learning</strong>: This model uses historical data to understand behaviour and formulate future forecasts. This kind of learning algorithms analyse any given training data set to draw inferences which can be applied to output values. Supervised learning parameters are crucial in mapping the input-output pair.</p></li>
<li><p><strong>Unsupervised machine learning</strong>: This type of ML algorithm does not use any classified or labelled parameters. It focuses on discovering hidden structures from unlabeled data to help systems infer a function properly. Algorithms with unsupervised learning can use both generative learning models and a retrieval-based approach.</p></li>
<li><p><strong>Semi-supervised machine learning</strong>: This model combines elements of supervised and unsupervised learning yet isn’t either of them. It works by using both labelled and unlabeled data to improve learning accuracy. Semi-supervised learning can be a cost-effective solution when labelling data turns out to be expensive.</p></li>
<li><p><strong>Reinforcement machine learnin</strong>g: This kind of learning doesn’t use any answer key to guide the execution of any function. The lack of training data results in learning from experience. The process of trial and error finally leads to long-term rewards.</p></li>
</ul>
<p><a class="reference external" href="https://www.youtube.com/watch?v=z-EtmaFJieY">Video:Machine Learning &amp; Artificial Intelligence</a></p>
</div>
<div class="section" id="machine-learning-in-a-nutshell">
<h2>Machine Learning in a nutshell<a class="headerlink" href="#machine-learning-in-a-nutshell" title="Permalink to this headline">¶</a></h2>
<p>Set of techniques for giving machines the ability to to find <strong>patterns</strong> and extract <strong>rules</strong> from data, in order to:</p>
<ul class="simple">
<li><p>Identify or classify elements</p></li>
<li><p>Detect tendencies</p></li>
<li><p>Make predictions</p></li>
</ul>
<p>As more data is fed into the system, results get better: performance improves with experience.</p>
<p>a.k.a. <strong>Statistical Learning</strong>.</p>
</div>
<div class="section" id="typology-of-ml-systems">
<h2>Typology of ML systems<a class="headerlink" href="#typology-of-ml-systems" title="Permalink to this headline">¶</a></h2>
<p>ML systems are traditionally classified in three categories, according to the amount and type of human supervision during training.</p>
<ul class="simple">
<li><p><strong>Supervised Learning</strong>: expected results (called <em>labels</em> or <em>tags</em>) are given to the system along with training data.</p></li>
<li><p><strong>Unsupervised Learning</strong>: training data comes without the expected results. The system must discover some structure in the data by itself.</p></li>
<li><p><strong>Reinforcement Learning</strong>: without being given an explicit goal, the system’s decisions produce a <strong>reward</strong> it tries to maximize.</p></li>
</ul>
</div>
<div class="section" id="classification-predicting-discrete-labels">
<h2>Classification: Predicting discrete labels<a class="headerlink" href="#classification-predicting-discrete-labels" title="Permalink to this headline">¶</a></h2>
<p>We will first take a look at a simple classification task, in which you are given a set of labeled points and want to use these to classify some unlabeled points.</p>
<p>Imagine that we have the data shown in this figure:</p>
<p><img alt="Table" src="_images/05.01-classification-1.png" /></p>
<p>Here we have two-dimensional data: that is, we have two features for each point, represented by the (x,y) positions of the points on the plane. In addition, we have one of two class labels for each point, here represented by the colors of the points. From these features and labels, we would like to create a model that will let us decide whether a new point should be labeled “blue” or “red.”</p>
<p>There are a number of possible models for such a classification task, but here we will use an extremely simple one. We will make the assumption that the two groups can be separated by drawing a straight line through the plane between them, such that points on each side of the line fall in the same group. Here the model is a quantitative version of the statement “a straight line separates the classes”, while the model parameters are the particular numbers describing the location and orientation of that line for our data. The optimal values for these model parameters are learned from the data (this is the “learning” in machine learning), which is often called training the model.</p>
<p>The following figure shows a visual representation of what the trained model looks like for this data:</p>
<p><img alt="Table" src="_images/05.01-classification-2.png" /></p>
<p>Now that this model has been trained, it can be generalized to new, unlabeled data.
In other words, we can take a new set of data, draw this model line through it, and assign labels to the new points based on this model.
This stage is usually called <em>prediction</em>. See the following figure:</p>
<p><img alt="Table" src="_images/05.01-classification-3.png" /></p>
<p>This is the basic idea of a classification task in machine learning, where “classification” indicates that the data has discrete class labels.
At first glance this may look fairly trivial: it would be relatively easy to simply look at this data and draw such a discriminatory line to accomplish this classification.
A benefit of the machine learning approach, however, is that it can generalize to much larger datasets in many more dimensions.</p>
<p>For example, this is similar to the task of automated spam detection for email; in this case, we might use the following features and labels:</p>
<ul class="simple">
<li><p><em>feature 1</em>, <em>feature 2</em>, etc. <span class="math notranslate nohighlight">\(\to\)</span> normalized counts of important words or phrases (“Viagra”, “Nigerian prince”, etc.)</p></li>
<li><p><em>label</em> <span class="math notranslate nohighlight">\(\to\)</span> “spam” or “not spam”</p></li>
</ul>
<p>For the training set, these labels might be determined by individual inspection of a small representative sample of emails; for the remaining emails, the label would be determined using the model.
For a suitably trained classification algorithm with enough well-constructed features (typically thousands or millions of words or phrases), this type of approach can be very effective.
We will see an example of such text-based classification</p>
<div class="section" id="regression-predicting-continuous-labels">
<h3>Regression: Predicting continuous labels<a class="headerlink" href="#regression-predicting-continuous-labels" title="Permalink to this headline">¶</a></h3>
<p>In contrast with the discrete labels of a classification algorithm, we will next look at a simple <em>regression</em> task in which the labels are continuous quantities.</p>
<p>Consider the data shown in the following figure, which consists of a set of points each with a continuous label:</p>
<p><img alt="Table" src="_images/05.01-regression-1.png" /></p>
<p>As with the classification example, we have two-dimensional data: that is, there are two features describing each data point.
The color of each point represents the continuous label for that point.</p>
<p>There are a number of possible regression models we might use for this type of data, but here we will use a simple linear regression to predict the points.
This simple linear regression model assumes that if we treat the label as a third spatial dimension, we can fit a plane to the data.
This is a higher-level generalization of the well-known problem of fitting a line to data with two coordinates.</p>
<p>We can visualize this setup as shown in the following figure:</p>
<p><img alt="Table" src="_images/05.01-regression-2.png" /></p>
<p>Notice that the <em>feature 1-feature 2</em> plane here is the same as in the two-dimensional plot from before; in this case, however, we have represented the labels by both color and three-dimensional axis position.
From this view, it seems reasonable that fitting a plane through this three-dimensional data would allow us to predict the expected label for any set of input parameters.
Returning to the two-dimensional projection, when we fit such a plane we get the result shown in the following figure:</p>
<p>This plane of fit gives us what we need to predict labels for new points. Visually, we find the results shown in the following figure:</p>
<p><img alt="Table" src="_images/05.01-regression-4.png" /></p>
<p>As with the classification example, this may seem rather trivial in a low number of dimensions.
But the power of these methods is that they can be straightforwardly applied and evaluated in the case of data with many, many features.</p>
<p>For example, this is similar to the task of computing the distance to galaxies observed through a telescope—in this case, we might use the following features and labels:</p>
<ul class="simple">
<li><p><em>feature 1</em>, <em>feature 2</em>, etc. <span class="math notranslate nohighlight">\(\to\)</span> brightness of each galaxy at one of several wave lengths or colors</p></li>
<li><p><em>label</em> <span class="math notranslate nohighlight">\(\to\)</span> distance or redshift of the galaxy</p></li>
</ul>
<p>The distances for a small number of these galaxies might be determined through an independent set of (typically more expensive) observations.
Distances to remaining galaxies could then be estimated using a suitable regression model, without the need to employ the more expensive observation across the entire set.
In astronomy circles, this is known as the “photometric redshift” problem.</p>
</div>
<div class="section" id="clustering-inferring-labels-on-unlabeled-data">
<h3>Clustering: Inferring labels on unlabeled data<a class="headerlink" href="#clustering-inferring-labels-on-unlabeled-data" title="Permalink to this headline">¶</a></h3>
<p>The classification and regression illustrations we just looked at are examples of supervised learning algorithms, in which we are trying to build a model that will predict labels for new data.
Unsupervised learning involves models that describe data without reference to any known labels.</p>
<p>One common case of unsupervised learning is “clustering,” in which data is automatically assigned to some number of discrete groups.
For example, we might have some two-dimensional data like that shown in the following figure:</p>
<p><img alt="Table" src="_images/05.01-clustering-1.png" /></p>
<p>By eye, it is clear that each of these points is part of a distinct group.
Given this input, a clustering model will use the intrinsic structure of the data to determine which points are related.
Using the very fast and intuitive <em>k</em>-means algorithm , we find the clusters shown in the following figure:</p>
<p><img alt="Table" src="_images/05.01-clustering-2.png" /></p>
<p><em>k</em>-means fits a model consisting of <em>k</em> cluster centers; the optimal centers are assumed to be those that minimize the distance of each point from its assigned center.
Again, this might seem like a trivial exercise in two dimensions, but as our data becomes larger and more complex, such clustering algorithms can be employed to extract useful information from the dataset.</p>
</div>
<div class="section" id="dimensionality-reduction-inferring-structure-of-unlabeled-data">
<h3>Dimensionality reduction: Inferring structure of unlabeled data<a class="headerlink" href="#dimensionality-reduction-inferring-structure-of-unlabeled-data" title="Permalink to this headline">¶</a></h3>
<p>Dimensionality reduction is another example of an unsupervised algorithm, in which labels or other information are inferred from the structure of the dataset itself.
Dimensionality reduction is a bit more abstract than the examples we looked at before, but generally it seeks to pull out some low-dimensional representation of data that in some way preserves relevant qualities of the full dataset.
Different dimensionality reduction routines measure these relevant qualities in different ways</p>
<p>As an example of this, consider the data shown in the following figure:</p>
<p><img alt="Table" src="_images/05.01-dimesionality-1.png" /></p>
<p>Visually, it is clear that there is some structure in this data: it is drawn from a one-dimensional line that is arranged in a spiral within this two-dimensional space.
In a sense, you could say that this data is “intrinsically” only one dimensional, though this one-dimensional data is embedded in higher-dimensional space.
A suitable dimensionality reduction model in this case would be sensitive to this nonlinear embedded structure, and be able to pull out this lower-dimensionality representation.</p>
<p>The following figure shows a visualization of the results of the Isomap algorithm, a manifold learning algorithm that does exactly this:</p>
<p><img alt="Table" src="_images/05.01-dimesionality-2.png" /></p>
<p>Notice that the colors (which represent the extracted one-dimensional latent variable) change uniformly along the spiral, which indicates that the algorithm did in fact detect the structure we saw by eye.
As with the previous examples, the power of dimensionality reduction algorithms becomes clearer in higher-dimensional cases.
For example, we might wish to visualize important relationships within a dataset that has 100 or 1,000 features.
Visualizing 1,000-dimensional data is a challenge, and one way we can make this more manageable is to use a dimensionality reduction technique to reduce the data to two or three dimensions.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Here we have seen a few simple examples of some of the basic types of machine learning approaches.
Needless to say, there are a number of important practical details that we have glossed over, but I hope this section was enough to give you a basic idea of what types of problems machine learning approaches can solve.</p>
<p>In short, we saw the following:</p>
<ul class="simple">
<li><p><em>Supervised learning</em>: Models that can predict labels based on labeled training data</p>
<ul>
<li><p><em>Classification</em>: Models that predict labels as two or more discrete categories</p></li>
<li><p><em>Regression</em>: Models that predict continuous labels</p></li>
</ul>
</li>
<li><p><em>Unsupervised learning</em>: Models that identify structure in unlabeled data</p>
<ul>
<li><p><em>Clustering</em>: Models that detect and identify distinct groups in the data</p></li>
<li><p><em>Dimensionality reduction</em>: Models that detect and identify lower-dimensional structure in higher-dimensional data</p></li>
</ul>
</li>
</ul>
<p>In the following sections we will go into much greater depth within these categories, and see some more interesting examples of where these concepts can be useful.</p>
<p>All of the figures in the preceding discussion are generated based on actual machine learning computations; the code behind them can be found in my github resource</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By <a href="https://fangli-ying.github.io/">Dr. Fangli Ying</a><br/>
    
        &copy; Copyright 2023.<br/>
      <div class="extra_footer">
        Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>